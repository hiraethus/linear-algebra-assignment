\documentclass{article}
\usepackage{amsmath}
\usepackage{hyperref}

\title{Linear Algebra Assignment}
\author{Michael J. Jones}


\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle

\section{Row and Column Picture of a linear model}

\subsection*{Solve the following linear system}

\begin{equation}
2x + y = 7
\end{equation}

\begin{equation}
2x + 3y = 1
\end{equation}

\subsubsection*{Answer}

Given we can express this problem in the form $Ax = b$:

<<>>=
A <- matrix(nrow = 2, data = c(2, 2, 1, 3))
colnames(A) <- c('x', 'y')
rownames(A) <- c('', '')
A

b <- matrix(nrow = 2, ncol = 1, data = c(7, 1))
colnames(b) <- c('')
rownames(b) <- c('', '')
b
@

Knowing that $x = A^{-1} \cdot b$, then

<<>>=
x = solve(A) %*% b
x
@

\subsection*{Draw the row picture of the linear system}

If we express y as a function of x in each of the above equations

\begin{gather}
f(x) = 7 - 2x \\
f(x) = \frac{1 - 2x}{3}
\end{gather}

Then, using the \emph{ggplot2} library, we can plot both of these functions in R.

<<fig=TRUE>>=
library(ggplot2)
library(grid)
# TODO
f.1 <- function(x) 7 - 2*x
f.2 <- function(x) (1 - 2*x) / 3

ggplot(data.frame(x=c(-10, 10)), aes(x)) +
  stat_function(fun=f.1, geom="line", aes(colour="2x + y = 7")) +
  stat_function(fun=f.2, geom="line", aes(colour="2x + 3y = 1")) +
  labs(title="Row Picture", colour="Linear functions") +
  theme(legend.position=c(0.85,0.9))
@

\subsection*{Draw the column picture of the linear system}

\subsubsection*{Answer}
In order to draw our column picture, it helps us to first express our problem as the summation of a set of vectors:

\begin{equation}
\begin{bmatrix}
2 \\
2
\end{bmatrix} x
+
\begin{bmatrix}
1 \\
3
\end{bmatrix} y
=
\begin{bmatrix}
7 \\
1
\end{bmatrix} x
\end{equation}

<<fig=TRUE>>=
ggplot(data.frame(x=c(-5, 10)), aes(x)) +
  geom_segment(colour="blue", aes(x = 0, y = 0, xend = 2, yend = 2), arrow = arrow(length = unit(0.5, "cm"))) +
  geom_segment(colour="red", aes(x = 0, y = 0, xend = 1, yend = 3), arrow = arrow(length = unit(0.5, "cm"))) +
  labs(title="Vectors") +
  xlab("x") +
  ylab("y") +
  geom_text(vjust=-.2, aes(label=c("v1", "v2")), x = c(1, 2), y = c(3,2))
@

Some combination of $x$ of the first vector and $y$ of the second vector will yield the third vector. Fortunately, 
we have already discovered when we solved this linear system that $x = 5$ and $y = -3$. This means that five of the 
first and negative three of the second vectors would add up to give us $(7, 1)'$.

<<fig=TRUE>>=
ggplot(data.frame(x=c(-5, 10)), aes(x)) +
  scale_x_continuous(limits = c(0, 12)) +
  geom_segment(colour="blue", aes(x = 0, y = 0, xend = 2, yend = 2),
               arrow = arrow(length = unit(0.5, "cm"))) +
  geom_segment(colour="red", aes(x = 0, y = 0, xend = 1, yend = 3),
               arrow = arrow(length = unit(0.5, "cm"))) +
  geom_segment(linetype="dashed", colour="blue",
               aes(x = 0, y = 0, xend = 2*5, yend = 2*5), 
               arrow = arrow(length = unit(0.5, "cm"))) +
  geom_segment(linetype="dashed", colour="red", 
               aes(x = 2*5, y = 2*5, xend = 2*5 - 3*1, yend = 2*5 - 3 * 3),
               arrow = arrow(length = unit(0.5, "cm"))) +
  geom_segment(size=1.5, colour="purple", aes(x = 0, y = 0, xend = 7, yend = 1),
               arrow = arrow(length = unit(0.5, "cm"))) +
  labs(title="Column Picture") +
  xlab("x") +
  ylab("y") +
  geom_text(vjust=-1,
            aes(label=c("v1", "v2", "(v2 * 5) + (v1 * -3)","")),
            x = c(1, 2, 7,0),
            y = c(3, 2, 1,0))

@

The column picture plainly shows that the combining v1 and v2 in the proportions of $5$ and $-3$ results in 
observing the vector, $(7,1)'$.

\section{Data}
All data is available at link \url{http://go.qub.ac.uk/toolkit/regularization}

\section{Linear regression model}

\subsection{Question}
Download and read the prostate cancer dataset prostate.data into a data matrix. The
data set is taken from the free online book \emph{The Elements of Statistical Learning} from
Trevor Hastie, Robert Tibshirani and Jerome Friedman. \\
\url{http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data}

\begin{verbatim}
Prostate data info
Predictors (columns 1--8)
lcavol
lweight
age
lbph
svi
lcp
gleason
pgg45

outcome (column 9)

lpsa

train/test indicator (column 10)
\end{verbatim}

\subsubsection*{Answer}

<<results=tex>>=
require(xtable) # install the xtable package if you don't have it
prostate.data.url <-
  "http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data"
prostate.data <- read.table(prostate.data.url, head=T)
xtable(head(prostate.data,3), )
@

\subsection{Question}
Estimate and define a linear model using the $lm()$ function.

\subsubsection*{Answer}

<<print=FALSE>>=
prostate.lm <- lm(formula = lpsa ~ ., data = prostate.data, method = "qr")
@

<<>>=
summary(prostate.lm)
@

\subsection{Question}
Split the prostate dataset into a test and training dataset (see column 10)

\subsubsection*{Answer}

<<results=tex>>=
split.data <- split(prostate.data, prostate.data$train)
prostate.training <- split.data$T
xtable(head(prostate.training,3), )

prostate.test <- split.data$F
xtable(head(prostate.test,3), )
@

\subsection{Question}
Predict $lpsa$ for the test example

\begin{verbatim}
data<-read.table(file="...")
# split data
test.data<- ...
train.data<- ...
\end{verbatim}

\subsubsection*{Answer}

\subsection{Question}
Plot your results (true $lpsa$ value $y_{i}$ and predicted $\hat{y}_{i}$).

\subsection{Question}
Repeat the analysis using a random forest regression and plot your results (true $lpsa$ value $y_{i}$ and predicted $\hat{y}_{i}$).


\end{document}